%!TEX root = ../data_poisoning.tex
\section{Атаки внедрением триггера (Backdoor)}
\subsection*{Цель}
Изменить набор обучающий данных $D$ таким образом, чтобы любое изображение, при наложении на него специального триггера классифицировалось в целевой класс $C'$.
При этом, также как и в случае обычных атак отравлением, нужно оказать как можно меньшее влияние на классификацию остальных изображений.

Примером триггера может быть помещение небольшого квадрата из чёрных или цветных пикселей в угол изображения.

\subsection*{Описание атак}

\textbf{Простая замена метки класса у отравленных изображений}
Также как и в случае обычных атак отравлением данных этот способ работает малоэффективно по тем же причинам.

\textbf{Clean-label backdoor}
Замена метки плоха ещё и тем, что посмотрев глазами на изображение можно легко убедиться, что на нём изображено не совпадает со значением метки класса.

Атака Clean-label backdoor заключается в том, чтобы уменьшить значимость всех иных признаков и заставить модель обращать максимальное внимание на триггер. Триггер при этом накладывается только на изображения класса $C'$, и таким образом метки классов остаются без изменения.

Для достижения поставленной цели могут быть использованы генеративные состязательные нейронные сети.
Пусть $G(z)$ – генератор, где $z$ – латентное представление изображения размерности $d$.

\noindentТогда найти латентное представление изображения $x$ можно по формуле:
$$E_{G}(x)=\arg \min _{z \in \mathbb{R}^{d}}\|x-G(z)\|_{2}$$

\noindentМы также можем сделать сдвиг в пространстве латентных представлений между двумя изображениям:
$$I_{G}\left(x_{1}, x_{2}, \tau\right)=G\left(\tau z_{1}+(1-\tau) z_{2}\right)$$

Где $\tau$ должно быть достаточно большим, чтобы снизить значимость признаков изображения, но достаточно маленьким, чтобы не быть заметным человеческому взгляду в отсутствии оригинала для сравнения.

% TODO: описать Adversarial examples bounded in `p-norm

\textbf{Hidden-trigger backdoor}
% TODO: описать Hidden-trigger backdoor

% \textbf{Deep Feature Space Trojan}
% Идея заключается в том чтобы сделать триггер более незаметным: для стороннего наблюдателя картинки с триггером и без него должны быть идентичны.
% Также триггер не должны обнаруживать системы, которые полагаются на
% то, что отравленные модели переобучаются на простые триггеры.
% TODO: разобраться можно ли применить без контроля обучения модели